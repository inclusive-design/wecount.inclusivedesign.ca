---
title: 'Bias In, Bias Out'
id: recoPfZIdOPjEYnpY
permalink: '/initiatives/recoPfZIdOPjEYnpY/'
eventDate: '2020-07-08'
shortDescription: >-
  Dr. Toon Calders (University of Antwerp) explains how predictions made using
  data mining and algorithms can affect population subgroups differently.


  July 8, 2020, 11:00 AM – 12:30 PM (EST)


  **Available badges:** Learner
previewImageUrl: >-
  https://dl.airtable.com/.attachments/bb73478c010ce54fd7ed24a56c37761c/fc2c448d/Group83.jpg
previewImageAltText: ''
coverImageUrl: >-
  https://dl.airtable.com/.attachments/596b9694d8abbed99f2c862120655183/3bcfa4c4/ToonCalders_Wordpress_2010x1052.png
coverImageAltText: >-
  Digging DEEPer Webinar on Machine Learning Discrimination by Dr. Toon Calders
  on July 8, 2020, 11AM-12PM
---
### **Machine Learning Discrimination: Bias In, Bias Out**

**Featuring Dr. Toon Calders**

July 8, 2020, 11:00 AM – 12:30 PM (EST)

Artificial intelligence is more and more responsible for decisions that have a huge impact on our lives. But predictions made using data mining and algorithms can affect population subgroups differently. Academic researchers and journalists have shown that decisions taken by predictive algorithms sometimes lead to biased outcomes, reproducing inequalities already present in society. Is it possible to make a fairness-aware data mining process? Are algorithms biased because people are too? Or is it how machine learning works at the most fundamental level?

[Bias In, Bias Out webinar video](https://youtu.be/NNrknIYLbrc)

### Earn a Learner badge

Machine learning, a subset of artificial intelligence, depends on the quality, objectivity and size of training data used to teach it. We Count encourages participants and learners to explore this concept to help inform more equitable decisions and supports by understanding data gaps and biases.

You will learn:

* How predictive algorithms and data mining affect different populations in a discriminatory manner
* How specific data resources are used to train and reinforce machine learning models to produce biased outputs  
    Learn and earn badges from this event:

1. Watch the accessible [Bias In, Bias Out webinar](https://youtu.be/NNrknIYLbrc)
2. [Apply for your Learner badge](https://factory.cancred.ca/c/earnablebadge/QFMWKWaFRa9OE/apply)

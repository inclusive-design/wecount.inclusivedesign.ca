---
title: "Decoupled Classifiers for Group-Fair and Efficient Machine Learning"
focus: "Methods or Design"
source: "FAT 2018"
readability: ["E"]
type: "PDF Article"
toolPurpose: []
toolAccessibilityIssues: []
openSource: false
sharePointUrl: "https://ocaduniversity.sharepoint.com/teams/Team_WeCount/Shared%20Documents/Resources%20and%20Tools/Literature%20(curated)/Decoupled%20Classifiers%20for%20Group-Fair%20and%20Efficient%20Machine%20Learning.pdf"
keywords: []
learnTags: ["bias","dataTools","methods","ethics","fairness","framework"]
summary: "A decoupling technique used to minimize or avoid bias and unfairness that can be added to any black-box machine learning algorithm to learn different classifier from different groups. "
---
When it is ethical and legal to use a sensitive attribute (such as gender or race) in
machine learning systems, the question remains how to do so. We show that the
naive application of machine learning algorithms using sensitive attributes leads to an inherent tradeoff in accuracy between groups. We provide a simple and efficient decoupling technique, which can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups. Transfer learning is used to mitigate the problem of having too little data on any one group.

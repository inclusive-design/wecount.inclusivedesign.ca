---
title: What Does It Mean to “Solve” the Problem of Discrimination in Hiring?
  Social, Technical and Legal Perspectives from the UK on Automated Hiring
  Systems
focus: Employment
source: FAT 2020
readability:
  - Expert
type: PDF Article
openSource: true
link: https://arxiv.org/pdf/1910.06144.pdf
learnTags:
  - bias
  - employment
  - machineLearning
  - methods
  - fairness
summary: The authors bring into scrutiny three automated hiring systems,
  HireVue, Pymetrics and Applied, to evaluate how they identify and alleviate
  bias and discrimination. These systems were chosen based on their claims to
  mitigate discriminatory hiring.
---
Discriminatory practices in recruitment and hiring are an ongoing issue that is a concern not just for workplace relations, but also for wider understandings of economic justice and inequality. The ability to get and keep a job is a key aspect of participating in society and sustaining livelihoods. Yet the way decisions are made on who is eligible for jobs, and why, are rapidly changing with the advent and growth in uptake of automated hiring systems (AHSs) powered by data-driven tools. Evidence of the extent of this uptake around the globe is scarce, but a recent report estimated that 98% of Fortune 500 companies use Applicant Tracking Systems of some kind in their hiring process, a trend driven by perceived efficiency measures and cost-savings. Key concerns about such AHSs include the lack of transparency and potential limitation of access to jobs for specific profiles. In relation to the latter, however, several of these AHSs claim to detect and mitigate discriminatory practices against protected groups and promote diversity and inclusion at work. Yet whilst these tools have a growing user-base around the world, such claims of ‘bias mitigation’ are rarely scrutinised and evaluated, and when done so, have almost exclusively been from a US socio-legal perspective.
---
title: "Biased Programmers? Or Biased Data? A Field Experiment in Operationalizing AI Ethics"
focus: "Bias"
source: "2020 NeurIPS"
readability: ["E"]
type: "PDF Article"
toolPurpose: []
toolAccessibilityIssues: []
openSource: false
link: "https://ocaduniversity.sharepoint.com/teams/Team_WeCount/Shared%20Documents/Resources%20and%20Tools/Literature%20(curated)/Biased%20Programmers%20Or%20Biased%20Data%20A%20Field%20Experiment%20in%20Operationalizing%20AI%20Ethics.pdf"
keywords: []
learnTags: ["ethics","bias","business"]
summary: "A study about the sources of bias among AI developers that stresses how more diverse teams will reduce the chance for compounding biases. "
---
Why do biased predictions arise? What interventions can prevent them? We evaluate 8.2 million algorithmic predictions of math performance from ≈ 400 AI engineers, each of whom developed an algorithm under a randomly assigned experimental condition. Our treatment arms modified programmers’ incentives, training data, awareness, and/or technical knowledge of AI ethics. We then assess out-of-sample predictions from their algorithms using randomized audit manipulations of algorithm inputs and ground-truth math performance for 20K subjects. We find that biased predictions are mostly caused by biased training data. However, one-third of the benefit of better training data comes through a novel economic mechanism: Engineers exert greater effort and are more responsive to incentives when given better training data. We also assess how performance varies with programmers’ demographic characteristics and their performance on a psychological test of implicit bias (IAT) concerning gender and careers. We find no evidence that female, minority and low-IAT engineers exhibit lower bias or discrimination in their code. However, we do find that prediction errors are correlated within demographic groups, which creates performance improvements through cross-demographic averaging. Finally, we quantify the benefits and tradeoffs of practical managerial or policy interventions such as technical advice, simple reminders, and improved incentives for decreasing algorithmic bias.

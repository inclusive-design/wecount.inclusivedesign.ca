---
title: "Modeling Epistemological Principles for Bias Mitigation in AI Systems:
  An Illustration in Hiring Decisions"
focus: Bias
source: "AAAI/ACM Conference on AI, Ethics, and Society "
readability:
  - Expert
type: PDF Article
openSource: true
link: "https://arxiv.org/pdf/1711.07111.pdf "
learnTags:
  - bias
  - business
  - methods
  - employment
  - fairness
  - framework
  - machineLearning
summary: With an increased reliance on AI in organizations' decision-making
  comes the elevated risk of discrimination and unfairness if left unchecked by
  organizations. Thus, the authors propose a two-level framework to mitigate
  bias in AI systems.
---
Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper’s contributions after Hume’s, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase.
---
title: "Improving Fairness in Machine Learning Systems: What Do Industry
  Practitioners Need?"
focus: AI Ethics/Policy
source: CHI 2019
readability:
  - Expert
type: Website Article
openSource: false
sharePointUrl: https://ocaduniversity.sharepoint.com/teams/Team_WeCount/Shared%20Documents/Resources%20and%20Tools/Literature%20(curated)/Improving%20fairness%20in%20machine%20learning%20systems-%20What%20do%20industry%20practitioners%20need.pdf
link: https://arxiv.org/abs/1812.05239
keywords:
  - algorithmic bias
  - fair machine learning
  - product teams
  - needfinding
  - empirical study
  - UX of machine learnin
learnTags:
  - bias
  - business
  - methods
  - ethics
  - fairness
  - inclusivePractice
  - solution
summary: "Through 35 semi-structured interviews and an anonymous survey of 267
  ML practitioners, the first systematic investigation of commercial product
  teams’ challenges and needs for support in developing fairer machine learning
  systems is presented.  "
---
The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of realworld needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams’ challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners’ needs.

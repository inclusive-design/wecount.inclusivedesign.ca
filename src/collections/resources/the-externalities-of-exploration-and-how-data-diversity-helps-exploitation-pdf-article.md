---
title: The Externalities of Exploration and How Data Diversity Helps Exploitation
focus: Methods or Design
source: COLT 2018
readability:
  - Expert
type: Website Article
openSource: false
link: https://arxiv.org/abs/1806.00543
keywords: []
learnTags:
  - dataset
  - methods
  - ethics
  - fairness
  - machineLearning
summary: "Online learning algorithms must balance exploration and exploitation,
  but recently, concerns have been raised about whether the process of
  exploration could be viewed as unfair, placing too much burden on certain
  individuals or groups. Motivated by these concerns, the externalities of
  exploration are studied, and the notion of a group externality is introduced,
  measuring the extent to which the presence of a majority group of users
  impacts the rewards of a minority group.  "
---
Online learning algorithms, widely used to power search and content optimization on the web, must balance exploration and exploitation, potentially sacrificing the experience of current users in order to gain information that will lead to better decisions in the future. Recently, concerns have been raised about whether the process of exploration could be viewed as unfair, placing too much burden on certain individuals or groups. Motivated by these concerns, we initiate the study of the externalities of exploration—the undesirable side effects that the presence of one party may impose on another—under the linear contextual bandits model. We introduce the notion of a group externality,measuring the extent to which the presence of one population of users (the majority) impacts therewards of another (the minority). We show that this impact can, in some cases, be negative, and that, in a certain sense, no algorithm can avoid it. We then move on to study externalities at the individual level, interpreting the act of exploration as an externality imposed on the current user ofa system by future users. This drives us to ask under what conditions inherent diversity in the data makes explicit exploration unnecessary. We build on a recent line of work on the smoothed analysis of the greedy algorithm that always chooses the action that currently looks optimal. We improve on prior results to show that a greedy approach almost matches the best possible Bayesian regretrate of any other algorithm on the same problem instance whenever the diversity conditions hold,and that this regret is at most ̃O(T1/3). Returning to group-level effects, we show that under the same conditions, negative group externalities essentially vanish if one runs the greedy algorithm. Together, our results uncover a sharp contrast between the high externalities that exist in the worst case, and the ability to remove all externalities if the datais sufficiently diverse.

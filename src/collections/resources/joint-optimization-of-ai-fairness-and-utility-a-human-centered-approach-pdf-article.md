---
title: "Joint Optimization of AI Fairness and Utility: A Human-Centered Approach"
focus: "AI Ethics/Policy"
source: "AIES 2020"
readability: ["Expert"]
type: "PDF Article"
toolPurpose: []
toolAccessibilityIssues: []
openSource: false
sharePointUrl: "https://ocaduniversity.sharepoint.com/teams/Team_WeCount/Shared%20Documents/Resources%20and%20Tools/Literature%20(curated)/Joint%20Optimization%20of%20AI%20Fairness%20and%20Utility-%20A%20Human-Centered%20Approach.pdf"
keywords: []
learnTags: ["bias","methods","ethics","fairness","framework","machineLearning","solution"]
summary: "A proposed framework to assist policy makers in choosing a machine learning model that maximizes fairness within the constraints of the policy. "
---
Today, AI is increasingly being used in many high-stakes decision-making applications in which fairness is an important concern.Already, there are many examples of AI being biased and makingquestionable and unfair decisions. The AI research community hasproposed many methods to measure and mitigate unwanted biases,but few of them involve inputs from human policy makers. Weargue that because different fairness criteria sometimes cannotbe simultaneously satisfied, and because achieving fairness oftenrequires sacrificing other objectives such as model accuracy, it iskey to acquire and adhere to human policy makersâ€™ preferenceson how to make the tradeoff among these objectives. In this paper,we propose a framework and some exemplar methods for elicitingsuch preferences and for optimizing an AI model according to thesepreferences.

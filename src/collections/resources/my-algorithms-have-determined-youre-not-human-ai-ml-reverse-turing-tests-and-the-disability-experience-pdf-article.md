---
title: "My Algorithms Have Determined Youâ€™re Not Human: AI-ML, Reverse
  Turing-Tests, and the Disability Experience"
focus: AI and Disability/Outliers
source: ASSETS 2019
readability:
  - Expert
type: PDF Article
openSource: false
sharePointUrl: https://ocaduniversity.sharepoint.com/teams/Team_WeCount/Shared%20Documents/Resources%20and%20Tools/Literature%20(curated)/My%20Algorithms%20Have%20Determined%20You're%20Not%20Human.pdf
link: https://escholarship.org/content/qt0t49r94h/qt0t49r94h.pdf
keywords:
  - Artificial intelligence
  - deep neural networks
  - disabilities
  - race
  - bias
learnTags:
  - bias
  - dataset
  - methods
  - disability
  - ethics
  - inclusivePractice
  - machineLearning
  - smallData
summary: A keynote presentation from the 2019 ASSETS conference that suggests
  diversity and inclusion need to be introduced at the start of the AI-ML design
  process, rather than as an afterthought.
---
The past decade has seen an exponential growth in the capabilities and deployment of artificial intelligence systems based on deep neural networks. These are visible through the speech recognition and natural language processing of Alexa/Siri/Google that structure many of our everyday interactions, and the promise of SAE Level 5 autonomous driving provided by Tesla and Waze. Aside from these shiny and visible applications of AI-ML are many other uses that are more subtle: AI-ML is now being used to screen job applicants as well as determine which web ads we are shown. And while many vendors of AI-ML technologies have promised that these tools provide for greater access and freedom from human prejudice, disabled users have found that these tools can embed and deploy newer, subtler forms of discrimination against disabled people. At their worst, AIML systems can deny disabled people their humanity.

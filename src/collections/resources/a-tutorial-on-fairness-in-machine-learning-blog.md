---
title: "A Tutorial on Fairness in Machine Learning"
focus: "Methods or Design"
source: "Towards Data Science"
readability: ["Expert"]
type: "Blog"
openSource: false
link: "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb"
keywords: []
learnTags: ["basicAI","bias","methods","ethics","fairness","inclusivePractice","machineLearning"]
summary: "This article highlights how unfairness in machine learning systems is mainly due to human bias existing in the training data. "
---
This post will be the first post on the series. The purpose of this post is to: 1. give a quick but relatively comprehensive survey of Fair ML. 2. provide references and resources to readers at all levels who are interested in Fair ML. The content is based on: the tutorial on fairness given by Solon Bacrocas and Moritz Hardt at NIPS2017, day1 and day4 from CS 294: Fairness in Machine Learning taught by Moritz Hardt at UC Berkeley and my own understanding of fairness literatures. I highly encourage interested readers to check out the linked NIPS tutorial and the course website. The current post consists of six parts: Introduction; Motivations; Causes of bias in ML; Definitions of fairness including formulation, motivations, example, and flaws, Algorithms used to achieve those fairness definitions, and Summary

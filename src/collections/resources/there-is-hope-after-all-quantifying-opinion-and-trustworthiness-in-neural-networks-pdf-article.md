---
title: "There Is Hope After All: Quantifying Opinion and Trustworthiness in
  Neural Networks"
focus: AI Ethics/Policy
source: Frontiers in Artificial Intelligence Journal
readability:
  - Expert
type: Website Article
openSource: true
sharePointUrl: https://ocaduniversity.sharepoint.com/teams/Team_WeCount/Shared%20Documents/Resources%20and%20Tools/Literature%20(curated)/There%20Is%20Hope%20After%20All.pdf
link: https://www.frontiersin.org/articles/10.3389/frai.2020.00054/full
keywords:
  - artificial intelligence
  - deep neural networks
  - machine learning
  - trust in AI
  - subjective logic
learnTags:
  - dataTools
  - ethics
  - framework
  - machineLearning
  - trust
summary: "An article that introduces DeepTrust, a new subjective logic framework
  that determines the trustworthiness of both data sets and their associated AI
  algorithms. "
---
Artificial Intelligence (AI) plays a fundamental role in the modern world, especially when used as an autonomous decision maker. One common concern nowadays is “how trustworthy the AIs are.” Human operators follow a strict educational curriculum and performance assessment that could be exploited to quantify how much we entrust them. To quantify the trust of AI decision makers, we must go beyond task accuracy especially when facing limited, incomplete, misleading, controversial or noisy datasets. Toward addressing these challenges, we describe DeepTrust, a Subjective Logic (SL) inspired framework that constructs a probabilistic logic description of an AI algorithm and takes into account the trustworthiness of both dataset and inner algorithmic workings. DeepTrust identifies proper multi-layered neural network (NN) topologies that have high projected trust probabilities, even when trained with untrusted data. We show that uncertain opinion of data is not always malicious while evaluating NN’s opinion and trustworthiness, whereas the disbelief opinion hurts trust the most. Also trust probability does not necessarily correlate with accuracy. DeepTrust also provides a projected trust probability of NN’s prediction, which is useful when the NN generates an over-confident output under problematic datasets. These findings open new analytical avenues for designing and improving the NN topology by optimizing opinion and trustworthiness, along with accuracy, in a multi-objective optimization formulation, subject to space and
time constraints.

---
title: Towards Trustable Explainable AI
focus: Methods or Design
source: IJCAI 2020
readability:
  - Expert
type: PDF Article
openSource: false
link: https://www.ijcai.org/Proceedings/2020/0726.pdf
learnTags:
  - machineLearning
  - trust
  - methods
summary: This paper explores the advances of rigorous abductive approaches to
  explainable AI and proffers that absolutely necessary if trustable explainable
  AI is of concern.
---
Explainable artificial intelligence (XAI) represents arguably one of the most crucial challenges being faced by the area of AI these days. Although the majority of approaches to XAI are of heuristic nature, recent work proposed the use of abductive reasoning to computing provably correct explanations for machine learning (ML) predictions. The proposed rigorous approach was shown to be useful not only for computing trustable explanations but also for validating explanations computed heuristically. It was also applied to uncover a close relationship between XAI and verification of ML models.